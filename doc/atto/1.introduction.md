# Introduction {#ch:introuction}

In antiquity, philosophy, mathematics and logic were considered as a single discipline. Since Aristotle we have realized that the world is not just black and white but full of nuances and colors. The inspiration for this thesis comes from one of the most influential philosophers and scientists of his time: Alfred Korzibsky. He founded a discipline he called *general semantics* to deal with problems of knowledge representation in humans. Korzibsky then found that complete knowledge of reality being inaccessible, we had to abstract. This abstraction is then only similar to reality in its structure. In these pioneering works, we find notions similar to that of modern descriptive languages.

It is from this inspiration that this document is built. We then start, off the beaten track and away from computer science by a brief excursion into the world of mathematical and logical formalism. This makes it possible to formalize a language that allows to describe itself partially by structure and that evolves with its use. The rest of the work illustrates the possible applications through specific fields such as automatic planning and intention recognition.

## Motivations

The social skills of modern robots are rather poor. Often, it is that lack that inhibits human-robot communication and cooperation. Humans being a social species, they require the use of implicit social cues in order to interact comfortably with an interlocutor.

In order to enhance assistance to dependent people, we need to account for any deficiency they might have. The main issue is that the patient is often unable or unwilling to express their needs. That is a problem even with human caregivers as the information about the patient's intents needs to be inferred from their past actions.

This aspect of social communications often eludes the understanding of Artificial Intelligence (AI) systems. This is the reason why intent recognition is such a complicated problem. The primary goal of this thesis is to address this issue and create the formal foundations of a system able to help dependent people.

## Problem

First, *what exactly is intent recognition ?* The problem is simple to express: finding out what other agents want to do before they do. It is important to distinguish between several notions. *Plans* are the sequence of actions that the agent is doing to achieve a *goal*. This goal is a concrete explanation of the wanted result. However, the *intent* is more of a set of abstract goals, some of which may be vague or impossible (e.g. drink something, survive forever, etc.).

Some approaches use trivial machine learning methods, along with a hand-made plan library match observations to their most likely plan to use statistics. The issue with these common approaches is that they require an extensive amount of training data and need to be trained on each agent. This makes the practicality of such system quite limited. To address this issue, some works proposed hybrid approaches using logical constraints on probabilistic methods. These constraints are made to guide the resolution toward a more coherent solution. However, all probabilistic methods require an existing plan library that can be quite expensive to create. Also, plan libraries cannot take into account unforeseen or unlikely plans.

A work from @ramirez_plan_2009, added an interesting method to solve this issue. Indeed, they noticed an interesting parallel between that problem with the field of automated planning. This analogy was made by using the Theory of mind [@baker_bayesian_2011], which states that any agent will infer the intent of other agents using a projection of their own expectations on the observed behaviors of the other agents.^[![](graphics/planning_vs_ir.svg)]

This made the use of planning techniques possible to infer intents without the need for extensive and well-crafted plan libraries. Now only the domain of the possible actions, their effects and prerequisites are needed to infer the logical intent of an agent.

The main issue of planning for that particular use is computation time and search space size. This prevents most planners to make any decision before the intent is already realized and therefore being useless for assistance. This time constraint leads to the search of a real-time planner algorithm that is also expressive and flexible.

## Contributions

In order to achieve such a planner, the first step was to formalize what is exactly needed to express a domain. Hierarchical and partially ordered plans gave the most expressivity and flexibility but at the cost of time and performance. This is why, a new formalism of knowledge representation was needed in order to increase the speed of the search space exploration while restricting it using semantic inference rules.

While searching for a knowledge representation model, we developed some prototypes using standard ontology tools but all proved to be too slow and inexpressive for that application. This made the design of a lighter but more flexible knowledge representation model, a requirement for planning domain representation.

Then the planning formalism has to be encoded using our general knowledge representation tool. Since automated planning has a very diverse ecosystem of approaches and paradigms, its standard, the Planning Domain Description Language (PDDL) needs use of various extensions. However, no general formalism has been given for PDDL and some approaches often lack proper extensions (hierarchical planning, plan representation, etc.). This is why a new formalism is proposed and compared to the one used as standard of the planning community.

Then finally, a couple of planners were designed to attempt answering the speed and flexibility requirements of human intent recognition. The first one is a prototype that aims to evaluate the advantages of repairing plans to use several heuristics. The second is a more complete prototype derived from the first (without plan repairs), which also implements a Breadth-First Search (BFS) approach to hierarchical decomposition of composite actions. This allows the planner to provide intermediary plans that, while incomplete, are an abstraction of the result plans. This allows for anytime intent recognition probability computation using existing techniques of inverted planning.

## Plan

In this document we will describe a few contributions from the new Structurally Expressive Language Framework for intent recognition. Each chapter builds on the previous one.

^[@Ch:fondation] First we will present a new mathematical model that suits our needs. This axiomatic theory is used to create a model capable of describing all the mathematical notions required for our work.

^[@Ch:self] In the third chapter, a new knowledge description system is presented as well as the associated grammar and inference framework. This system is based on triple representation to allow for structurally defined semantic.

^[@Ch:planning] The @ch:planning is an introduction to automated planning along with a formal description of a general planner using appropriate search spaces and solution constraints.

^[@Ch:color] The fifth chapter is an application of knowledge description to automated planning. This allows us to design a general planning framework that can express any existing type of domain. Existing languages are compared to our proposed approach.

^[@Ch:heart] Using this framework, two online planning algorithms are presented in chapter six: one that uses repairs on existing plans and one that uses hierarchical domains to create intermediary abstract plans.

^[@Ch:rico] The final chapter is about intent recognition and its link to planning. Existing works are presented as well as a technique called *inverted planning*.
