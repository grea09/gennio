---
title: "3. Heart"
author: Antoine Gréa
bibliography: bibliography/thesis.bib
style: thesis
---

# Online and Flexible Planning Algorithms

## Existing Algorithms

État de l'art

## Lollipop

### Operator Graph

### Negative Refinements

### Usefullness Heuristic

### Algorithm

### Theoretical and Empirical Results

## HEART

### Domain Compilation

### Abstraction in POP

### Planning in cycle

### Properties of Abstract Planning

### Computational Profile

## Planning Improvements

### Heuristics using Semantics

### Macro-Action learning

## Recognition

### Existing approcahes

### Rico


#### Probabilities and approximations

We define a probability distribution over dated states of the world. That distribution is in part given and fixed and the rest needs computation. **TODO : that's super bad…**

Here is the list of given prior probabilities and asumptions :

* $P(O)=\prod_{o\in O} P(o)$
* $P(\mathcal{G}) = \sum_{G\in \mathcal{G}}P(G) = 1$ since we assume that the agent must be pursuing one of the goals.
* $P(G|\pi) = 1$ for a plan $\pi$ appliable in $I$ that achieves $G$.

From dirrect application of Bayes theorem and the previous assomptions, we have :

$$ P(\pi|O) = \frac{P(O|\pi) P(\pi)}{P(O)} = \frac{P(O|\pi) P(\pi|G) P(G)}{P(O)}$$ {#eq:plan-obs}

$$ P(G|O) = \frac{P(O|G)P(G)}{P(O)}$$ {#eq:goal-obs}

From the total probability formula :

$$P(O|G) = \sum_{\pi \in \Pi_G} P(O|\pi) P(\pi|G)$$ {#eq:obs-goal}$$P(O|G) = \sum_{\pi \in \Pi_G} P(O|\pi) P(\pi|G)$$ {#eq:obs-goal}
