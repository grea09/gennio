# Toward intent recognition

Since the original goal of this thesis was on intent recognition of dependant persons, we need to explain some more about that specific domain. The problem is to infer the goals of an external agent through only observations without intervention. In the end, the idea is to infer that goal confidently enough to start assisting the other agent without explicit instructions.


## Domain problems

This field was widely studied. Indeed, at the end of the last century, several works started using *abduction* to infer intents from observational data. Of course this comes as a chalenge since there is a lot of uncertainty involved. We have no reliable information on the possible goals of the other agent and we don't have the same knowledge of the world. Also, observations can sometimes be incomplete or misleading, the agent can abandon goals or pursue several goals at once while also doing them suboptimally or even fail at them. To finish, someimes agents can actively try to hide their intents to the viewer.

### Observations and inferences

As explained above, we can only get close to reality and any progress in
relevance and detail is exponentially expensive in terms of computing
and memory resources. That is why any system will maintain a high degree
of abstraction that will cause errors inherent in this approximation.

This noise phenomenon can impact the activity and situation recognition
system and therefore seriously impact the intention recognition and
decision making system with an amplification of the error as it is
processed. It is also important to remember that this phenomenon of data
noise is also present in inhibition and that the lack of perception of
an event is as disabling as the perception of the wrong event.

It is possible to protect recognition systems in an appropriate way, but
this often implies a restriction on the levels of possibilities offered
by the system such as specialized recognition or recognition at a lower
level of relevance.

### Cognitive inconsistencies

In the field of personal assistance, activity recognition is a crucial
element. However, it happens that these events are very difficult to
recognize. The data noise mentioned above can easily be confused with an
omission on the part of the observed agent. This dilemma is also present
during periods of inactivity, the system can start creating events from
scratch to fill what it may perceive as inhibition noise.

These problems are accompanied by others related to the behaviour of the
observed agent. For example, they may perform unnecessary steps, restart
ongoing activities or suddenly abandon them. It is added that other
aspects of observations can make automated inferences such as ambiguous
actions or the agent performing an action that resembles another
complicated.

However, some noise problems can be easily detected by simple cognitive
processes such as impossible sequences (e. g. closing a closed door).
Contextual analyses provide a partial solution to some of these
problems.

### Sequentiality

Since our recognition is based on a highly temporal planning aspect, we
must take into account the classic problems of sequentiality.

A first problem is to determine the end of one plan and the beginning of
another. Indeed, it is possible that some transitions between two planes
may appear to be a plane in itself and therefore may cause false
positives. Another problem is that of intertwined planes. A person can
do two things at once, such as answering the phone while cooking. An
action in an intertwined plan can then be identified as a
discontinuation of activity or a logical inconsistency. A final problem
is that of overloaded actions. Not only can an agent perform two tasks
simultaneously, but also perform an action that contributes to two
activities. These overloaded actions make the process of intention
recognition complex because they are close to data noise.

## Existing approaches

The problem of intention recognition has been strongly addressed from
many angles. It is therefore not surprising that there are many
paradigms in the field. The first studies on the subject highlight the
fact that intention recognition problems are problems of abductive logic
or graph coverage. Since then, many models have competed in imagination
and innovation to improve the field. These include constraint
system-based models that provide a solution based on pre-established
rules and compiled plan libraries, those that use state or action
networks that then launch algorithms on these data, and reverse planning
systems.

### Constraint

One of the approaches to intention recognition is the one that builds a
system around a strong logical constraint. There is often a time
constraint system that is complemented by various extensions to cover as
many sequential problems as possible.

In order to solve a problem of intention recognition, abductive logic
can be used. Contrary to deductive logic, the goal is to determine the
objective from the observed actions. Among the first models introduced
is @goldman_new_1999's model, which uses the principle of action to
construct a logical representation of the problem. This paradigm
consists in creating logical rules as if the action in question were
actually carried out, but in hypothesizing the predicates that
concretize the action and thus being able to browse the research space
thus created in order to find all the possible plans containing the
observed actions and concretizing defined intentions. This model is
strongly based on first-order logic and SWI Prolog logic programming
languages. Although revolutionary for the time, this system pale in
comparison to recent systems, particularly in terms of prediction
accuracy.

Some paradigms use algebra to determine possible plans from observed
actions. In particular, we find the model of @bouchard_smart_2006 which extends the subsumption
relationship from domain theory to the description of action and
sequence of action in order to introduce it as an order relationship in
the context of the construction of a lattice composed of possible plans
considering the observed actions. This model simply takes into account
the observed actions and selects any plan from the library of plans that
contains at least one observed action. Then this paradigm will construct
all the possible plans that correspond to the Cartesian product of the
observed actions with the actions contained in the selected plans (while
respecting their order). This system makes it possible to obtain a
subsumption relationship that corresponds to the fact that the plans are
more or less general. Unfortunately, this relationship alone does not
provide any information on which plan is most likely.

That is why @roy_possibilistic_2011 created a probabilistic extension of this model.
This uses frequency data from a system learning period to calculate the
influence probabilities of each plane in the recognition space. This
makes it possible to calculate probabilistic intervals for each plan,
action as well as for a plan knowing a given action. In order to
determine the probability of each plane knowing the upper bound of the
lattice (plane containing all observed actions) the sum of the
conditional probabilities of the plane for each observed action divided
by the number of observed actions is made. This gives a probability
interval for each plane allowing the ordinates. This model has the
advantage of considering many possible plans but has the disadvantage of
seeing a computational explosion as soon as the number of observed
actions increases and the context is not taken into account.

Another approach is that of grammar. Indeed, we can consider actions as
words and sequences as sentences and thus define a system that allows us
to recognize shots from incomplete sequences. @vidal_online_2010 has therefore
created a system of intention recognition based on grammar. It uses the
evaluated grammar system to specify measurements from observations.
These measures will make it possible to select specific plans and thus
return a hierarchical hypothesis tree with the actions already carried
out, the future and the plans from which they are derived. This model is
very similar to first order logic-based systems, and uses a SWI Prolog
type logic language programming system. Given the scope of maritime
surveillance, this model, although taking very well into account the
context and the evolution of the measures, is only poorly adapted to an
application in assistance, particularly in the absence of a system for
discriminating against results plans.

Another class of approaches is that of diverting standard
problem-solving tools to solve the problem of intention recognition. It
is therefore possible, by modifying traditional algorithms or by
transforming a problem, to ensure that the solution of the tool
corresponds to the one sought.

@inoue_ilpbased_2011 develops the idea of a model that uses linear
programming to solve the recognition problem. Indeed, observations are
introduced in the form of causes in relation to hypotheses, in a
first-order logic predicate system. Each atom is then weighted and
introduced into a process of problem transformation by feedback and the
introduction of order and causality constraints in order to force the
linear program towards optimal solutions by taking into account
observations. Although ingenious, this solution does not discriminate
between possible plans and is very difficult to apply to real-time
recognition situations, mainly because of the problem transformation
procedure required each time the problem is updated.

Another constraint paradigm is the one presented by @raghavana_plan
using a Markovian extension of first-order logic. The model consists of
a library of plans represented in the form of Horn clauses indicating
which actions imply which intentions. The aim is therefore to reverse
the implications in order to transform the deduction mechanism into an
abduction mechanism. Exclusionary constraints and a system of weights
acquired through learning must then be introduced to determine the most
likely intention. Once again, despite the presence of a system of result
discrimination, there is no consideration of context and abductive
transformation remains too cumbersome a process for real-time
recognition.

### Networks

As in its early days, intention recognition can still be modeled in the
form of graphs. Very often in intention recognition, trees are used to
exploit the advantages of acyclicity in resolution and path algorithms.
In the prolific literature of Geib et al. we find the model at the basis
of PHATT [@geib_problems_2002] which consists of an AND/OR tree representing a
HTN that contains the intentions as well as
their plans or methods. A prior relationship is added to this model and
it is through this model that constraints are placed on the execution of
actions. Once an action is observed, all the successors of the action
are unlocked as potential next observed action. We can therefore infer
by hierarchical path the candidate intentions for the observed sequence.

Since this model does not allow discrimination of results, @geib_partial_2005 then adds probabilities to the explanations of the
observations. The degree of coverage of each possible goal is used to
calculate the probability of each goal. That is, the goal with the plan
containing the most observed action and the least unobserved action will
be the most likely. This is very ingenious, as the coverage rate is one
of the most reliable indicators. However, the model only takes into
account temporality and therefore has no contextual support. The
representation in the form of a tree also makes it very difficult to be
flexible in terms of the plans, which are then fixed a priori.

The RTH model is often used in the field, such as the hierarchical tree
form used by @avrahami-zilberbrand_fast_2005. The tree consists of nodes that
represent various levels of action and intent. A hierarchical
relationship links these elements together to define each intention and
its methods. To this tree is added an anteriority relationship that
constrains the execution order. This paradigm uses time markers that
guarantee order using an actualisation algorithm that also updates a
hypothesis tree containing possible intentions for each observation.

A probabilistic extension of the @avrahami-zilberbrand_hybrid_2006 applies a
hierarchical hidden Markov model to the action tree. Using three types
of probability, that of plan tracking, execution interleaving and
interruption, we can calculate the probability of execution of each plan
according to the observed sequence. The logic and contextual model
filtered on the possible plans upstream leaving us with few calculations
to order these plans.

This contextual model uses a decision tree
based on a system of world properties. Each property has a finite (and
if possible very limited) number of possible values. This allows you to
create a tree containing for each node a property and an arc for each
value. This is combined with other nodes or leaves that are actions.
While running through the tree during execution, the branches that do
not correspond to the current value of each property are pruned. Once a
leaf is reached, it is stored as a possible action. This considerably
reduces the research space but requires a balanced tree that is not too
large or restrictive.

When we approach stochastic models, we very often find Markovian or
Bayesian models. These models use different probabilistic tools ranging
from simple probabilistic inference to the fusion of stochastic
networks. It can be noted that probabilities are often defined by
standard distributions or are isomorphic to weighted systems.

A stochastic model based on THRs is the one presented by @blaylock_fast_2006. This creates hierarchical stacks to categorize abstraction
levels from basic actions to high level intentions. By chaining a hidden
Markov model to these stacks, the model is able to affect a probability
of intention according to the observed action.

Another stochastic paradigm is the one of @han_contextdependent_2013. It uses Bayesian
networks to define relationships between causes, intentions and actions
in a given field. Each category is treated separately in order to reduce
the search space. The observed actions are then selected from the action
network and extracted. The system then uses the intention network to
build a temporary Bayesian network using the NoisyOR method. The network
created is combined in the same way with the network of causes and makes
it possible to give the intention as well as the most probable cause
according to the observations.

The model of @kelley_contextbased_2012 (based on [@hovland_skill_1996]) is a model using hidden
Markov networks. This stochastic network is built here by learning data
from robotic perception systems. The goal is to determine intent using
past observations. This model uses the theory of mind by invoking that
humans infer the intentions of their peers by using a projection of
their own.

Another contextual approach is the one developed for robotics by @hofmann_intent_2007. The stochastic system is completed by a weighting based on
an analysis of vernacular corpuses. We can therefore use the context of
an observation to determine the most credible actions using the
relational system built with corpus analysis. This is based on the
observation of the objects in the scene and their condition. This makes
common sense actions much more likely and almost impossible actions
leading to semantic contradictions.

This principle is also used as the basis of the paradigm of @baker_modeling_2014 which forms a Bayesian theory of the mind. Using a limited
representation of the human mind, this model defines formulas for
updating beliefs and probabilities a posteriori of world states and
actions. This is constructed with sigmoid distributions on the simplex
of inferred belief. Then the probabilities of desire are calculated in
order to recover the most probable intention. This has been validated as
being close to the assessment of human candidates on simple intention
recognition scenarios.

## Inverted planning

Another way to do intent recognition is to use the *theory of mind*. This theory states that an agent recognizes other agent's behavior by projecting its own beliefs, desires and intentions on the other agent. This particular model is called BDI fo Belief, Desire and Intention. In our case the belief part is the knowledge database and planning domain. The desires are the set of available goals and the intent is the plan to pursue a set of goals.

This way of doing intent recognition is called "inverse planning" because it is the inversed problem of planning. In planning we get a goal and we need to find a plan to achieve it, and in intent recognition, we got an observed plan and we search for the goals.

This approach first emerged with the work of @ramirez_plan_2009. This article uses a classical planner to compute the most probable goal given a sequence of actions. This uses constraints to make the cost of a plan correlate with its likelyhood.

### Probabilities and approximations

In that section we explain how this operation is done.

For any set of observations $\cal{O}$ the probability of the set is the product of the probability of any observation $o \in \cal{O}$. We can then note $\bb{P}(\cal{O})=\prod_{o\in \cal{O}} \bb{P}(o)$.

We assume that the observed agent is pursuing one of the knowns goals. The event of an agent pursuing a goal is noted $g$. This means that $\bb{P}(\cal{G}) = \sum_{g\in \cal{G}}\bb{P}(\cal{G}) = 1$ because the event is certain.

Using conditional probabilities we can also note  $\bb{P}(\cal{G}|\pi) = 1$ for a valid plan $\pi$ that achieves $G$.

From dirrect application of Bayes theorem and the previous assomptions, we have :

$$ P(\pi|O) = \frac{P(O|\pi) P(\pi)}{P(O)} = \frac{P(O|\pi) P(\pi|G) P(G)}{P(O)}$$ {#eq:plan-obs}

$$ P(G|O) = \frac{P(O|G)P(G)}{P(O)}$$ {#eq:goal-obs}

And from the total probability formula :

$$P(O|G) = \sum_{\pi \in \Pi_G} P(O|\pi) P(\pi|G)$$ {#eq:obs-goal}


